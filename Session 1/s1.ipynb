{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69696de6",
   "metadata": {},
   "source": [
    "# Session 1: Data Preprocessing with the Titanic Dataset\n",
    "\n",
    "In this notebook, we will:\n",
    "- Load and explore the Titanic dataset  \n",
    "- Identify and handle missing values  \n",
    "- Encode categorical variables  \n",
    "- Scale numerical features  \n",
    "- Split the data into training and testing sets  \n",
    "\n",
    "Dataset source: `seaborn.load_dataset(\"titanic\")`\n",
    "\n",
    "### Titanic Dataset: Variable Description\n",
    "\n",
    "The Titanic dataset contains information about passengers on the Titanic and whether they survived the disaster.  \n",
    "Below is a short description of each column:\n",
    "\n",
    "| Column | Type | Description |\n",
    "|---------|------|-------------|\n",
    "| **survived** | int (0 = No, 1 = Yes) | Whether the passenger survived. This will be our target variable in later sessions. |\n",
    "| **pclass** | int (1, 2, 3) | Passenger class — a proxy for socioeconomic status (1st = upper, 2nd = middle, 3rd = lower). |\n",
    "| **sex** | category | Gender of the passenger (`male`, `female`). |\n",
    "| **age** | float | Age of the passenger in years. May contain missing values. |\n",
    "| **sibsp** | int | Number of siblings or spouses aboard the Titanic. |\n",
    "| **parch** | int | Number of parents or children aboard the Titanic. |\n",
    "| **fare** | float | Ticket fare paid by the passenger (in British pounds). |\n",
    "| **embarked** | category | Port of embarkation (`C` = Cherbourg, `Q` = Queenstown, `S` = Southampton). May contain missing values. |\n",
    "| **class** | category | Duplicate of `pclass`, but stored as a categorical variable (`First`, `Second`, `Third`). |\n",
    "| **who** | category | Simplified description of the passenger (`man`, `woman`, `child`). |\n",
    "| **adult_male** | bool | Whether the passenger is an adult male (True/False). |\n",
    "| **deck** | category | Deck level where the passenger’s cabin was located. Many values are missing. |\n",
    "| **embark_town** | category | Full name of the embarkation town (`Cherbourg`, `Queenstown`, `Southampton`). Similar to `embarked`. |\n",
    "| **alive** | category | Text version of survival status (`yes` / `no`). |\n",
    "| **alone** | bool | Whether the passenger traveled alone. |\n",
    "\n",
    "\n",
    "**Note:**  \n",
    "For our preprocessing exercises, we will mainly use the following variables:\n",
    "- `age`, `fare`, `sibsp`, `parch` → numerical features  \n",
    "- `sex`, `class`, `embarked` → categorical features  \n",
    "- `survived` → target variable for later modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a5002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "\n",
    "# Display first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac028ef",
   "metadata": {},
   "source": [
    "## Exploring the Titanic Dataset\n",
    "\n",
    "Let's start by inspecting the structure of our data:\n",
    "- What are the column names?\n",
    "- What types of variables do we have?\n",
    "- Are there any missing values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73539c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6136c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ed4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5db37e7b",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "1. Check how many unique values each column has.  \n",
    "2. Identify which columns are categorical and which are numerical.  \n",
    "3. Plot one or two distributions (e.g., `age`, `fare`) using `sns.histplot`.\n",
    "\n",
    "*Hint:* use `df.nunique()` and `sns.histplot(df['age'])`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14950a96",
   "metadata": {},
   "source": [
    "**1. Check how many unique values each column has**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac589c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e02e75a3",
   "metadata": {},
   "source": [
    "**2. Identify which columns are categorical and which are numerical.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac73f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5845a5ac",
   "metadata": {},
   "source": [
    "**3. Plot one or two distributions (e.g., `age`, `fare`) using `sns.histplot`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa29531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f078cb",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Let's look closer at missing data:\n",
    "- The `age` column has some missing entries.\n",
    "- The `embarked` column also contains missing values.\n",
    "\n",
    "We can:\n",
    "1. Drop rows or columns with too many NaNs.\n",
    "2. Fill (impute) missing values with mean, median, or most frequent values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432a387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb390ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33683979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd359dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04befa0e",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Try to:\n",
    "1. Inspect the `deck` and `embark_town` columns.  \n",
    "2. Decide how you would handle their missing values.  \n",
    "3. Apply your chosen strategy (drop, fill, and how to fill).\n",
    "\n",
    "*Discuss your reasoning:* When is it better to drop vs impute?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c5d06",
   "metadata": {},
   "source": [
    "**1. Inspect the `deck` and `embark_town` columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376d502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bea84e9",
   "metadata": {},
   "source": [
    "**2. Decide how you would handle their missing values.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a015c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0f0966b",
   "metadata": {},
   "source": [
    "**3. Apply your chosen strategy (drop, fill, and how to fill).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71bdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3c775bc",
   "metadata": {},
   "source": [
    "**Bonus exercise: try imputation using interpolate for numerical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a2225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9f1754b",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "\n",
    "Machine learning models require numerical input.\n",
    "We need to **encode** categorical variables such as `sex`, `class`, and `embarked`.\n",
    "\n",
    "Common approaches:\n",
    "- **Label encoding:** assign integer IDs (good for ordinal categories)\n",
    "- **One-Hot encoding:** create binary columns for each category (good for nominal categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5695f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64f57890",
   "metadata": {},
   "source": [
    "### Exercise 3 – Encoding Categorical Variables\n",
    "\n",
    "So far, we’ve seen how to use **One-Hot Encoding** to convert categorical features into binary variables.  \n",
    "Now let’s go deeper and compare it with **Label Encoding**.\n",
    "\n",
    "1. Identify which categorical columns are **ordinal** (with a meaningful order) and which are **nominal** (no inherent order).   \n",
    "2. Apply **Label Encoding** to the ordinal feature(s).  \n",
    "3. Apply **One-Hot Encoding** to the nominal feature(s).  \n",
    "4. Combine all encoded columns into a single processed dataset with the numerical variables.  \n",
    "5. Compare the two encoding methods — what are the pros and cons of each?\n",
    "\n",
    "*Hint:*  \n",
    "You can use `sklearn.preprocessing.LabelEncoder` for label encoding and `OneHotEncoder` for one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0001067",
   "metadata": {},
   "source": [
    "**1. Identify which categorical columns are **ordinal** (with a meaningful order) and which are **nominal** (no inherent order).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af114f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e54d8426",
   "metadata": {},
   "source": [
    "**2. Apply **Label Encoding** to the ordinal feature(s).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b7b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc7968e",
   "metadata": {},
   "source": [
    "**3. Apply **One-Hot Encoding** to the nominal feature(s).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08ecc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e250604",
   "metadata": {},
   "source": [
    "**4. Combine all encoded columns into a single processed dataset with the numerical variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0811cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5f5be65",
   "metadata": {},
   "source": [
    "**5. Compare the two encoding methods — what are the pros and cons of each?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493faeb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fceaec2e",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Many ML algorithms (e.g., k-NN, SVM, gradient descent-based methods) are sensitive to feature scale.  \n",
    "Common techniques:\n",
    "- **Standardization (Z-score):** subtract mean, divide by std.\n",
    "- **Min–Max scaling:** rescale to [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed933e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ea16e3",
   "metadata": {},
   "source": [
    "### Exercise 4 – Compare Feature Scaling Methods\n",
    "\n",
    "So far, we’ve applied **StandardScaler**, which rescales features to have a mean of 0 and standard deviation of 1.\n",
    "\n",
    "1. Apply **MinMaxScaler** to the same dataset.  \n",
    "2. Compare the results between StandardScaler and MinMaxScaler.  \n",
    "3. Visualize the effect of both scaling methods on a feature (e.g., `fare`).  \n",
    "4. Discuss: when might one method be preferred over the other?\n",
    "\n",
    "*Hints:*\n",
    "- Use `from sklearn.preprocessing import MinMaxScaler`.\n",
    "- The Min–Max formula rescales features to a fixed range, typically [0, 1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d395f3",
   "metadata": {},
   "source": [
    "**1. Apply **MinMaxScaler** to the same dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e6516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "648670af",
   "metadata": {},
   "source": [
    "**2. Compare the results between StandardScaler and MinMaxScaler.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b89537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e891b28f",
   "metadata": {},
   "source": [
    "**3. Visualize the effect of both scaling methods on a feature (e.g., `fare`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692028f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a254090",
   "metadata": {},
   "source": [
    "**4. Discuss: when might one method be preferred over the other?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea995be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1193d7e5",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "We now have a clean, encoded, and scaled dataset.\n",
    "Let’s split it into **training** and **testing** subsets to prepare for modeling.\n",
    "\n",
    "- `train_test_split` ensures models can generalize.  \n",
    "- Typical ratio: 80 % training / 20 % testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9ae72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fba51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d92bc4",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "1. Repeat the split using `test_size=0.3` and then `0.5`.  \n",
    "2. Observe how the size of the training set changes.  \n",
    "3. What happens if we change the random_state parameter?\n",
    "4. Discuss: what are the trade-offs between a larger training or test set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7981b",
   "metadata": {},
   "source": [
    "**1. Repeat the split using `test_size=0.3` and then `0.5`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92877ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a7a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1ca4dcc",
   "metadata": {},
   "source": [
    "**2. Observe how the size of the training set changes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c1df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c0a8ffe",
   "metadata": {},
   "source": [
    "**3. What happens if we change the random_state parameter?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650b8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87bad699",
   "metadata": {},
   "source": [
    "**4. Discuss: what are the trade-offs between a larger training or test set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d86702",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26d5df01",
   "metadata": {},
   "source": [
    "## Advanced Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71575f",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Visualize missing data patterns to understand missing data visually.\n",
    "\n",
    "Use sns.heatmap() to visualize where missing values occur.\n",
    "\n",
    "Identify if missingness appears random or systematic (e.g., people in certain classes missing ages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521798e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5aa4036",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Explore outliers before and after scaling to understand how scaling interacts with outliers.\n",
    "\n",
    "Identify potential outliers with boxplots and compare before/after scaling (StandardScaler, MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb1805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4cc4057",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Explore correlation between variables.\n",
    "\n",
    "Compute correlation matrix of numeric variables. Plot it with sns.heatmap().\n",
    "\n",
    "Which features are most correlated? Could that affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea9767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a6b98c",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "Build a preprocessing pipeline that helps you consolidate all preprocessing steps and allows you to reuse it for new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92e074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "551dbcd7",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "Apply all the steps (or use the pipeline developed by yourself in *Exercise 9*) in order to preprocess a new dataset.\n",
    "\n",
    "Proposed dataset: `sns.load_dataset(\"penguins\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24f7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "128d8a7b",
   "metadata": {},
   "source": [
    "### Bonus: Practice on a custom dataset\n",
    "\n",
    "Apply the learned skills to your own personal research data.\n",
    "\n",
    "1. Bring a small CSV dataset from your own project.\n",
    "2. Load it using pd.read_csv() and repeat:\n",
    "    - Missing value handling\n",
    "    - Encoding categorical variables\n",
    "    - Scaling\n",
    "    - Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46401151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
