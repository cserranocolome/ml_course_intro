{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ded4a30",
   "metadata": {},
   "source": [
    "# Session 2 – Supervised Learning\n",
    "\n",
    "In this notebook, we will:\n",
    "- Understand the concept of regression and classification\n",
    "- Train a Linear Regression model using scikit-learn\n",
    "- Evaluate model performance with appropriate metrics\n",
    "- Visualize predictions vs real values\n",
    "- Train and evaluate a Logistic Regression classifier\n",
    "- Experiment with alternative classifiers\n",
    "\n",
    "Dataset source:  **Diabetes dataset** and **Breast Cancer dataset** included in scikit-learn.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792938b",
   "metadata": {},
   "source": [
    "## Part 1: Regression with the Diabetes Dataset\n",
    "\n",
    "We’ll use the **Diabetes dataset** included in scikit-learn.  \n",
    "It contains data from patients with diabetes, including clinical measurements such as age, BMI, blood pressure, and blood serum variables.  \n",
    "\n",
    "Our goal will be to **predict disease progression** (a continuous target variable) based on these features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "df['target'] = diabetes.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1217ee",
   "metadata": {},
   "source": [
    "### Inspect and Prepare the Data\n",
    "\n",
    "Do we need any preprocessing this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae607058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic info\n",
    "print(df.info())\n",
    "\n",
    "# Basic statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38035d",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "\n",
    "We’ll separate our dataset into:\n",
    "- **Features (X)**: the 10 clinical variables  \n",
    "- **Target (y)**: the disease progression measure  \n",
    "\n",
    "Then we’ll split it into training and test sets to evaluate performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d7f01",
   "metadata": {},
   "source": [
    "### Train a Linear Regression Model\n",
    "\n",
    "We’ll use **LinearRegression** from scikit-learn, which fits a straight line to predict a continuous target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068dfde",
   "metadata": {},
   "source": [
    "Let's first try to fit a regression with only the age variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e21986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train_age = X_train[['age']]\n",
    "X_test_age = X_test[['age']]\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_age, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(X_test_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc37b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91327e",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "We’ll use **Mean Squared Error (MSE)** and **R² score** to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f2987",
   "metadata": {},
   "source": [
    "### Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"True vs Predicted Disease Progression\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed4a8d",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "1. Compute now a linear regression using all the features from the dataset\n",
    "2. What does the model learn? Are coefficients positive or negative? What might that mean biologically?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e4182",
   "metadata": {},
   "source": [
    "**1. Compute now a linear regression using all the features from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5c755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a77be05",
   "metadata": {},
   "source": [
    "**2. What does the model learn? Are coefficients positive or negative? What might that mean biologically?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f225d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e901ed",
   "metadata": {},
   "source": [
    "### Exercise 2: Compute R² score, MAE and RMSE\n",
    "\n",
    "Add two more evaluation metrics: \n",
    "\n",
    "1. R² score\n",
    "2. Mean Absolute Error (MAE)\n",
    "3. Root Mean Squared Error (RMSE)\n",
    "4. Compare these values for train and for test. Which one is better?\n",
    "\n",
    "*Hint:* from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43f456",
   "metadata": {},
   "source": [
    "**1. R² score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cc39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efc9d57e",
   "metadata": {},
   "source": [
    "**2. Mean Absolute Error (MAE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9e477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a907c804",
   "metadata": {},
   "source": [
    "**3. Root Mean Squared Error (RMSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e8ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c5fd3d1",
   "metadata": {},
   "source": [
    "**4. Compare these values for train and for test. Which one is better?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debca3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683047ab",
   "metadata": {},
   "source": [
    "### Exercise 3: Plot again the predictions vs targets\n",
    "\n",
    "Are the results better this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa99c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842b35ea",
   "metadata": {},
   "source": [
    "### Exercise 4: Inspect the Residuals\n",
    "\n",
    "The residuals are defined as the difference between the true values and the predicted values. \n",
    "\n",
    "1. Visualize the residuals in a histrogram. \n",
    "2. Plot a scatterplot of the residuals vs the predicted. \n",
    "\n",
    "Are the residuals centered around 0? Is there any pattern (heteroscedasticity)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299a336",
   "metadata": {},
   "source": [
    "**1. Visualize the residuals in a histrogram.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca625e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "990ea432",
   "metadata": {},
   "source": [
    "**2. Plot a scatterplot of the residuals vs the predicted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfb8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b11c6e38",
   "metadata": {},
   "source": [
    "### Exercise 5: Try Ridge Regression\n",
    "\n",
    "Ridge regression adds regularization to reduce overfitting.\n",
    "\n",
    "1. Import and train a Ridge() model.\n",
    "2. Look at the coefficients this time. How do they compare to the Linear Regression?\n",
    "3. Compare its R² score with LinearRegression.\n",
    "\n",
    "*Hint:* from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c9394",
   "metadata": {},
   "source": [
    "**1. Import and train a Ridge() model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395a977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64039c55",
   "metadata": {},
   "source": [
    "**2. Look at the coefficients this time. How do they compare to the Linear Regression?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6845eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "530fdbae",
   "metadata": {},
   "source": [
    "**3. Compare its R² score with LinearRegression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc75a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1937110a",
   "metadata": {},
   "source": [
    "### Exercise 6: Hyperparameter Tuning for Ridge\n",
    "\n",
    "Use a small loop to see how alpha affects regularization and performance. What would be the optimal alpha range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b4917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e48939b",
   "metadata": {},
   "source": [
    "### Exercise 7: Experiment also with Lasso\n",
    "\n",
    "Try out Lasso regression and compare it with the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10178fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "729e72c4",
   "metadata": {},
   "source": [
    "### Exercise 8: Feature Importance\n",
    "\n",
    "Sort and plot the regression coefficients to see which features contribute most.\n",
    "\n",
    "*Hint:* Use sns.barplot() with the coefficients DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ae290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7408d9d",
   "metadata": {},
   "source": [
    "## Additional Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74becf3",
   "metadata": {},
   "source": [
    "### Exercise 9: Polynomial Regression\n",
    "\n",
    "Use PolynomialFeatures(degree=2) to add interaction terms and see if performance improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82917f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e478b160",
   "metadata": {},
   "source": [
    "### Exercise 10: Feature Scaling Comparison\n",
    "\n",
    "Compare model performance with and without StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecfd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9ae1369",
   "metadata": {},
   "source": [
    "## Part 2: Classification with the Breast Cancer Dataset\n",
    "\n",
    "We’ll use the **Breast Cancer dataset** included in scikit-learn.  \n",
    "This dataset contains **diagnostic features** of breast tissue (e.g., radius, texture, symmetry), computed from digitized images of fine needle aspirates (FNA) of breast masses.\n",
    "\n",
    "The task is to predict whether a tumor is **malignant (1)** or **benign (0)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf11dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = cancer.target\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe().T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7642e4",
   "metadata": {},
   "source": [
    "Let's check the distribution of the targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c483501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95820017",
   "metadata": {},
   "source": [
    "### Split into Training and Test Sets\n",
    "\n",
    "We’ll use an 80/20 split for training and testing.\n",
    "\n",
    "This time we use *stratify=y* to maintain the same class proportion in both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd13f51",
   "metadata": {},
   "source": [
    "### Train a Logistic Regression Classifier\n",
    "\n",
    "Logistic Regression models the **probability** of belonging to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73739437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=5000, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # probability for class 1 (malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cancer.target_names)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03bdc1",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "1. Use K nearest neighbors to perform the classification\n",
    "2. Plot the confusion matrix and compare it from the one obtained for the logistic regression.\n",
    "3. (Optional) Try scaling features before fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c18f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8904ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79924e7a",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "1. Do the same using Decision Trees. Important: Setting max_depth helps prevent overfitting.\n",
    "2. Plot feature importance.\n",
    "3. Decision Trees are intuitive and interpretable — they learn “if–then” rules. Visualie the tree and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2daeb6e",
   "metadata": {},
   "source": [
    "**1. Do the same using Decision Trees. Important: Setting max_depth helps prevent overfitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94289ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9acf53f3",
   "metadata": {},
   "source": [
    "**2. Plot feature importance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e8162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37fa78db",
   "metadata": {},
   "source": [
    "**3. Decision Trees are intuitive and interpretable — they learn “if–then” rules. Visualie the tree and interpret.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1278ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8572ca35",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "1. Do the same using Random Forest.\n",
    "2. Plot feature importance.\n",
    "3. Compare with the results obtained from the Decision Tree. What are the main differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9056592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e72ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "410ace8f",
   "metadata": {},
   "source": [
    "### Exercise 4: Hyperparameter Search\n",
    "\n",
    "1. Try different max_depth for the Decision tree model. Which number is the best choice?\n",
    "2. Try different number of trees for the Random Forest model. Which number is the best?\n",
    "3. Is overfitting noticeable?\n",
    "\n",
    "*Hint: maybe it is convenient to look into from sklearn.model_selection import GridSearchCV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40f732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e95827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
